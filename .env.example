# OpenAI API Configuration
# Required for using OpenAI GPT models (GPT-5.1, GPT-4, etc.)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here

# Optional: Custom OpenAI API base URL (for proxies or compatible services)
# OPENAI_BASE_URL=https://api.openai.com/v1

# Optional: Default OpenAI model to use
# OPENAI_MODEL=gpt-4


# Anthropic API Configuration
# Required for using Claude models (Claude Sonnet 4.5, Claude Opus, etc.)
# Get your API key from: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# Optional: Custom Anthropic API base URL (for proxies or compatible services)
# ANTHROPIC_BASE_URL=https://api.anthropic.com


# Default Provider Configuration
# Uncomment to set a default provider for CLI commands
# Options: openai, anthropic, claude, mock
# PROVIDER=openai

# Default Model Configuration
# Uncomment to set default models for each provider
# Note: Model names are examples - check provider docs for current model names
# OPENAI_MODEL=gpt-4
# CLAUDE_MODEL=claude-3-opus-20240229


# Generator Configuration
# Default settings for the LLM that generates responses
# GENERATOR_PROVIDER=openai  # Provider for generation (openai, anthropic, claude, mock)
# GENERATOR_MODEL=gpt-4  # Model for generation
# TEMPERATURE=0.7  # Generator temperature (0.0-2.0, higher = more random)
# MAX_COMPLETION_TOKENS=1024  # Maximum tokens for generator responses
# SEED=42  # Optional: for reproducible outputs (provider-dependent)


# Judge Configuration
# Settings for the LLM that evaluates generated outputs
# Judge model typically uses temperature=0.0 for consistent scoring
# Can use same or different provider/model than generator
# JUDGE_PROVIDER=openai  # Can differ from generator provider
# JUDGE_MODEL=gpt-4  # Model for evaluation
# JUDGE_TEMPERATURE=0.0  # Judge temperature (should be 0.0 for deterministic scoring)
# JUDGE_MAX_COMPLETION_TOKENS=512  # Maximum tokens for judge responses


# JSON Schema Validation
# Optional: Default JSON schema file for structured output validation
# Path can be absolute or relative to config file
# JSON_SCHEMA=schemas/response_format.json

# Note on Schema Paths:
# - Relative paths are resolved from current working directory or config file location
# - Absolute paths work across environments: /home/user/project/schemas/schema.json
# - CLI --json-schema flag overrides this default
# - See docs/datasets.md for schema authoring guidance


# Run Configuration
# Default directory for evaluation run artifacts
# RUN_DIRECTORY=runs
